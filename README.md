# ğŸ“ MFTTransfer

MFTTransfer is a distributed file transfer system designed to move large files between MFT nodes efficiently and reliably. It supports both **one-to-one** and **one-to-many** transfers, ensuring **resumability**, **parallel downloads**, and **scalability** across multiple nodes.

This project was built in response to a system design challenge focused on performance, fault tolerance, and high availability during multi-node file transmission.

---

## ğŸ§© Architecture Overview

- **MFTTransfer.Api** â€“ Exposes endpoints for initiating uploads and managing transfer sessions.
- **MFTTransfer.BackgroundJobs** â€“ Hosts Kafka consumers and background handlers for chunk processing, retries, and status tracking.
- **MFTTransfer.Domain** â€“ Contains data models, enums, and interfaces for clean architecture boundaries.
- **MFTTransfer.Infrastructure** â€“ Houses caching logic (Redis, memory), blob storage access, Kafka services, and reusable helpers.
- **MFTTransfer.Monitoring** â€“ Implements Prometheus-based metrics and logging.
- **MFTTransfer.Utilities** â€“ Utility functions for chunking, compression, hashing, and Redis helpers.

---

## ğŸš€ Features

- ğŸ” **Reliable transfers** with resumable support (tracked by Redis)
- âš¡ **Parallel chunk uploading/downloading** for speed
- ğŸ“¡ **Kafka-based communication** between nodes
- ğŸ’¾ **Blob storage** via Azurite (or Azure Blob in production)
- ğŸ” **Prometheus metrics** integration
- ğŸ”„ **Retry handlers** for failed chunks
- ğŸ”’ Designed for **high availability** and **horizontal scalability**

---

## ğŸ“‚ Folder Highlights

| Project                          | Key Responsibilities                                      |
|----------------------------------|-------------------------------------------------------------|
| `MFTTransfer.Api`               | REST API to initiate and control file transfers             |
| `MFTTransfer.BackgroundJobs`    | Kafka consumers, chunk handlers, retry logic                |
| `MFTTransfer.Domain`            | Data models: `ChunkMessage`, `FileMetadata`, etc.           |
| `MFTTransfer.Infrastructure`    | Services: Kafka, Blob, Redis, caching, constants, interfaces|
| `MFTTransfer.Monitoring`        | `PrometheusMetrics`, `LogCollector`                         |
| `MFTTransfer.Utilities`         | Helpers: chunking, hashing, compression                     |

---

## ğŸ”„ File Transfer Flow

### ğŸ”¹ Direct Transfer (MFT_A â†’ MFT_B)

1. MFT_A splits the file into chunks.
2. Each chunk is uploaded to Azurite blob storage.
3. A message is sent to Kafka with transfer metadata.
4. MFT_B listens and downloads each chunk in parallel.
5. Redis tracks the status of downloaded chunks for resumability.

### ğŸ”¹ One-to-Many Transfer (MFT_A â†’ MFT_B, MFT_C)

1. MFT_A uploads once and publishes to Kafka.
2. All subscribed nodes (e.g., MFT_B, MFT_C) begin downloading concurrently.
3. Each node independently tracks its download status via Redis.

---

## âš™ï¸ Tech Stack

- **.NET Core 6++**
- **Kafka** (message queue for inter-node events)
- **Redis** (state tracking for chunk progress)
- **Azurite / Azure Blob Storage**
- **Prometheus** (metrics collection)
- **Docker** (recommended for local setup)

---

## ğŸ§ª How to Run (Local Dev)

```bash
# 1. Clone the repository
git clone https://github.com/tuanlevunhat/MFTTransfer.git
cd MFTTransfer

# 2. Ensure you have:
# - Docker running (for Kafka, Redis, Azurite)
# - .NET 6 SDK installed

# 3. Build & run the services
dotnet build
dotnet run --project MFTTransfer.Api

# 4. Setup other services (background jobs, etc.)
dotnet run --project MFTTransfer.BackgroundJobs
